{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_datareader import data, wb\n",
    "from datetime import datetime\n",
    "#cor plot index use is inconsistant with some other function maybe HRP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run /Users/davidfitzpatrick/Desktop/Codes/Python_codes/Finance_codes/tools/helpers.ipynb\n",
    "\n",
    "#read in stock data\n",
    "#tickers = ['SPY', 'SPYC']\n",
    "#start = datetime(2020,1,1)\n",
    "#end = datetime(2021,7,20)\n",
    "#returns = import_data(tickers,start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "def windowed_view(x, window_size):\n",
    "    \"\"\"Creat a 2d windowed view of a 1d array.\n",
    "\n",
    "    `x` must be a 1d numpy array.\n",
    "\n",
    "    `numpy.lib.stride_tricks.as_strided` is used to create the view.\n",
    "    The data is not copied.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    >>> x = np.array([1, 2, 3, 4, 5, 6])\n",
    "    >>> windowed_view(x, 3)\n",
    "    array([[1, 2, 3],\n",
    "           [2, 3, 4],\n",
    "           [3, 4, 5],\n",
    "           [4, 5, 6]])\n",
    "    \"\"\"\n",
    "    y = as_strided(x, shape=(x.size - window_size + 1, window_size),\n",
    "                   strides=(x.strides[0], x.strides[0]))\n",
    "    return y\n",
    "\n",
    "def max_dd(ser):\n",
    "    max2here = ser.cummax()\n",
    "    dd2here = ser - max2here\n",
    "    return dd2here.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Turbulence_indicator(returns): #reduces dataset by 15 days because covariance matrix is unstable before that\n",
    "    turbulence=[]\n",
    "    for i in range(15,len(returns)):\n",
    "        deviation = returns.iloc[i]-returns[:i].mean() #[:i] prevents information bleed\n",
    "        inverse = np.linalg.inv(returns[:i].cov())     #[:i] prevents information bleed\n",
    "        turb = np.sqrt(np.matmul(np.matmul(deviation.T,inverse),deviation))\n",
    "        turbulence.append(turb)\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    AllData = returns[15:]\n",
    "    AllData['Turbulence']=turbulence\n",
    "    pd.options.mode.chained_assignment = 'warn'  # default='warn'\n",
    "    return AllData\n",
    "\n",
    "#Turbulence indicator- I use the square root because the magnitude of the indicator is higher for daily data\n",
    "#starts 15 days in for stability reasons. inverse covariance matrix is large and sometimes negative for small sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run C:\\Users\\avid\\Desktop\\Python_codes\\Finance_codes\\tools\\helpers.ipynb\n",
    "#tickers = ['TLT', 'IVV']\n",
    "#start = datetime(2003,1,1)\n",
    "#end = datetime(2020,7,31)\n",
    "#returns = import_data(tickers,start,end, give =\"R\", dividend=True)\n",
    "\n",
    "#TIP: use join when have dataframes of different lengths and just want to keep the intersection of rows\n",
    "\n",
    "\n",
    "# plot dividends\n",
    "    # pd.DataFrame(port[\"IVV_Div\"]/port[\"IVV\"]).resample('AS').sum().plot()\n",
    "\n",
    "# annualize returns\n",
    "    # returns.resample(\"A\").apply(lambda x: ((x + 1).cumprod()-1).last(\"D\"))\n",
    "\n",
    "#for company info\n",
    "    #si.get_quote_table(\"SPY\", dict_result = False)\n",
    "\n",
    "# get weekday\n",
    "    # week['weekday'] = week['Date'].apply(lambda x: x.weekday())\n",
    "    \n",
    "#bid ask info \n",
    "    #si.get_quote_table(\"SPY\", dict_result = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr(leader, follower, graph_bounds, plot=False, title=\"Title\"):\n",
    "\n",
    "    x = np.arange(len(leader))\n",
    "    y1 = follower\n",
    "    y2 = leader\n",
    "    npts = len(y1)\n",
    "\n",
    "    lags = np.arange(-npts + 1, npts)\n",
    "    ccov = np.correlate(y1 - y1.mean(), y2 - y2.mean(), mode='full')\n",
    "    ccor = ccov / (npts * y1.std() * y2.std())\n",
    "\n",
    "    #fig, axs = plt.subplots(nrows=2)    \n",
    "    #fig.subplots_adjust(hspace=0.4)   \n",
    "    #ax = axs[0]   \n",
    "    #ax.plot(x, y1, 'b', label='Follower')\n",
    "    #ax.plot(x, y2, 'r', label='Leader')    \n",
    "    #ax.set_ylim(-.1, 1)    \n",
    "    #ax.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "\n",
    "    if(plot==True):\n",
    "        fig, axs = plt.subplots(nrows=1)\n",
    "        ax = axs#[1]\n",
    "        ax.plot(lags[graph_bounds:-graph_bounds], ccor[graph_bounds:-graph_bounds]) #npts-1, npts-1\n",
    "        ax.set_ylim(-.7, .9)\n",
    "        ax.set_ylabel('Correlation')\n",
    "        ax.set_xlabel('Days between Leader and Follower')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    maxlag = np.argmax(ccor[:])#npts-1\n",
    "    maxcorr = np.max(ccor[:])#npts-1\n",
    "    print(title,\": Max correlation is at lag\", maxlag-npts+1,\"\\nCorrelation is\", round(maxcorr,2)) \n",
    "    # from following https://currents.soest.hawaii.edu/ocn_data_analysis/_static/SEM_EDOF.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(regressor, data, start, end): #Monthly beta\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    #from sklearn.base import clone\n",
    "    #import sklearn\n",
    "    lm = LinearRegression()\n",
    "    riskfree = 'VFISX' #VFISX is a poor risk_free rate maturity currently being 3 years, but it's convenient\n",
    "    #returns = import_data([regressor,riskfree]+tickers,start,end, give =\"R\",dividend=True) alt method\n",
    "    returns_internal = import_data([regressor,riskfree],start,end, give =\"R\",dividend=True)\n",
    "    all_data = returns_internal.join(data,how='inner')\n",
    "    for col in (all_data.columns):\n",
    "        all_data[col] = all_data[col]-all_data[riskfree]\n",
    "    adjusted = all_data.drop(riskfree,axis=1).resample(\"M\").apply(lambda x: ((x + 1).cumprod()-1).last(\"D\"))\n",
    "    \n",
    "    coef=[]\n",
    "    for col in (adjusted.columns[1:]):\n",
    "        X = np.array(adjusted[regressor]).reshape(-1,1)\n",
    "        y = np.array(adjusted[col]).reshape(-1,1)\n",
    "        lm.fit(X,y) #use all data as training data because we arn't predicting anything\n",
    "        coef.append(lm.coef_[0])\n",
    "        \n",
    "    coeff_df = pd.DataFrame(coef,columns=[\"Beta\"]).set_index(adjusted.columns[1:]) \n",
    "    print(coeff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed allocation backtest with chosen rebalance schedule\n",
    "\n",
    "def backtest(wealth, weights, col, dataf, days_between_rebalance, RebalanceOffset=0, give='R'): #cols allows users to backtest subsets of dataframe\n",
    "    \n",
    "    colin=[0]*len(weights)\n",
    "    port=[0]*len(weights)\n",
    "    worth=[wealth]\n",
    "\n",
    "    for n in range(len(weights)):\n",
    "        colin[n] = dataf.columns.get_loc(col[n])\n",
    "        port[n]=wealth*weights[n]\n",
    "\n",
    "    for n in range (len(dataf)):\n",
    "        for i in range(len(weights)):\n",
    "            port[i]=port[i]*(1+dataf.iloc[n,colin[i]])\n",
    "\n",
    "        end_of_day = sum(port)\n",
    "        \n",
    "        worth.append(end_of_day)\n",
    "        if ((n + RebalanceOffset)% days_between_rebalance==0):        #rebalance  \n",
    "            \n",
    "            for i in range(len(weights)): port[i] = end_of_day * weights[i]\n",
    "    if (give=='R'):            \n",
    "        p_rtn = pd.DataFrame(worth).pct_change()[1:].set_index(dataf.index)\n",
    "        return(p_rtn)\n",
    "    if (give=='D'):\n",
    "        return(pd.DataFrame(worth[1:]).set_index(dataf.index))\n",
    "    \n",
    "\n",
    "#def backtest(wealth,weights,col, data, days_between_rebalance): #cols allows users to backtest subsets of dataframe\n",
    "#    colin=[0]*len(weights)\n",
    "#    port=[0]*len(weights)\n",
    "#    worth=[wealth]\n",
    "#\n",
    "#    for n in range(len(weights)):\n",
    "#        colin[n] = data.columns.get_loc(col[n])\n",
    "#        port[n]=wealth*weights[n]\n",
    "#\n",
    "#    for n in range (len(data)):\n",
    "#        for i in range(len(weights)):\n",
    "#            port[i]=port[i]*(1+data.iloc[n,colin[i]])\n",
    "#\n",
    "#        end_of_day = sum(port)\n",
    "#        \n",
    "#        \n",
    "#        if (n % days_between_rebalance==0):        #rebalance  \n",
    "#            worth.append(end_of_day)\n",
    "#            for i in range(len(weights)): port[i] = end_of_day * weights[i]\n",
    "#                \n",
    "#    p_rtn = pd.DataFrame(worth).pct_change()[1:].reset_index().drop([\"index\"],axis=1)\n",
    "#    \n",
    "#    return(p_rtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IR_or_yield_curve(start,end,plot=True):\n",
    "    \n",
    "    if (plot==True):\n",
    "        Interest_rates = ['^IRX','^TNX'] # '^FVX', '^TYX'\n",
    "        IR = import_data(Interest_rates,start,end, give =\"S\", dividend=True)\n",
    "        IR[\"yd_cve\"]=IR[\"^TNX\"]-IR[\"^IRX\"]\n",
    "        IR[\"yd_cve\"].plot()\n",
    "        plt.title(\"10 year - 3 month rate\")\n",
    "        plt.show(block=True)\n",
    "    if (plot==False):\n",
    "        Interest_rates = ['^IRX','^FVX','^TNX','^TYX']\n",
    "        IR = import_data(Interest_rates,start,end, give =\"S\", dividend=True)\n",
    "        return IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IR_swap(rec_int, pay_int, rec_yr, pay_yr, rec_principal, pay_principal,length, FX_rate):\n",
    "    FX_rates=[FX_rate]\n",
    "    pay_cashflow=[]\n",
    "    rec_cashflow=[]\n",
    "    net_cashflow=[]\n",
    "    present_val=[]\n",
    "    for n in range (1, length+1):\n",
    "        FX_rates.append(FX_rate*m.exp((pay_int-rec_int)*n))\n",
    "        pay_cashflow.append(pay_principal*pay_yr)\n",
    "        rec_cashflow.append(rec_principal*rec_yr)\n",
    "    pay_cashflow.append(pay_principal)\n",
    "    rec_cashflow.append(rec_principal)\n",
    "    del FX_rates[0]\n",
    "    FX_rates.append(FX_rates[n-1])\n",
    "    for n in range (0,length+1):\n",
    "        net_cashflow.append(rec_cashflow[n]*FX_rates[n]+pay_cashflow[n])\n",
    "    for n in range(0,length):\n",
    "        present_val.append(net_cashflow[n]*m.exp(-pay_int*(n+1)))\n",
    "    present_val.append(net_cashflow[n+1]*m.exp(-pay_int*(n+1)))\n",
    "    print(sum(present_val))\n",
    "    \n",
    "    #assumes term structure is flat, rates are continuously compounded\n",
    "\n",
    "#rec_int        #interest risk free rate of currency recieving\n",
    "#pay_int        #interest risk free rate of currency paying\n",
    "#rec_yr         #yearly interest rate agreed upon which the company is recieving\n",
    "#pay_yr         #yearly interest rate agreed upon which the company is paying\n",
    "#rec_principal  #principle amount agreed in currency company is recieving\n",
    "#pay_principal  #principle amount agreed in currency company is paying\n",
    "#length         #years left in contract\n",
    "#FX_rate        #ratio FX rate: currency paid/currency recieved\n",
    "\n",
    "#Note: output is in units of currency which the company pays\n",
    "#ex IR_swap(.04,.09,.05,.08,1200,-10,3,1/110)\n",
    "\n",
    "#rec  yen\n",
    "#pay   dollars\n",
    "#present value is in currency paying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_return(data):\n",
    "    return data.cumprod()[-1:].abs()**(1/(data[-1:].index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#growth of 1 dollar invested\n",
    "\n",
    "def dollar_growth(returns): # dates come directly from the returns provided so dates might be off one from expected\n",
    "    how=np.ones([len(returns),len(returns.columns)])\n",
    "    for n in range(1,len(returns)):\n",
    "        for i in range(len(returns.columns)):\n",
    "            how[n,i]=how[n-1,i]*(1+returns.iloc[n-1,i])\n",
    "    how=pd.DataFrame(how)\n",
    "    how.columns=returns.columns\n",
    "    how.index=returns.index\n",
    "    return how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the monthly time series of correlation\n",
    "\n",
    "def cor_plot(start_year, end_year, dataset, SandP,lines_per_plot,num_plots,lower_y):\n",
    "    cor = pd.DataFrame()\n",
    "    month = [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n",
    "    i=0\n",
    "    j=0\n",
    "    for j in np.arange(start_year,end_year+1):\n",
    "        for i in np.arange(1,13):\n",
    "            cor[month[i-1]+str(j)] = correlation(dataset,SandP,datetime(j,i,1), datetime(j,i,28))       \n",
    "    for i in np.arange(0,num_plots,1):\n",
    "        print(cor[i:i+lines_per_plot].T.rolling(4).mean().plot().set_ylim(lower_y, 1))\n",
    "        \n",
    "def correlation(dataset,SandP,start,end):\n",
    "    return dataset[start:end].corr()[SandP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(tickers,start,end, give =\"R\", dividend=True):#read in stock data  \n",
    "    SPY = data.DataReader('SPY', 'yahoo', start, end)[\"Close\"]\n",
    "    stocks = pd.DataFrame()\n",
    "    stock_div = pd.DataFrame(SPY).drop(\"Close\",axis=1)\n",
    "    for tick in tickers:\n",
    "        stocks[tick] = data.DataReader(tick, 'yahoo', start, end)[\"Close\"]\n",
    "        if (dividend == True): \n",
    "            stock_div[tick+' div'] = data.DataReader(tick, 'yahoo-dividends', start, end)[\"value\"]\n",
    "      \n",
    "    just_stocks=stocks\n",
    "    if (dividend == True):\n",
    "        stocks = pd.concat([stocks,stock_div],axis=1)\n",
    "        stocks = stocks.fillna(0)\n",
    "        \n",
    "    if(give == \"R\"):\n",
    "        #Adding dividends to price appreciation on a daily percent return basis -useful for all analysis\n",
    "        raw_returns=pd.DataFrame()\n",
    "        for tick in tickers:\n",
    "            if (dividend == True):\n",
    "                raw_returns[tick] = stocks[tick].pct_change() + stocks[tick+' div']/stocks[tick] \n",
    "                #dividends are actually added on the day before they should be added but this error is neglegible\n",
    "            else:\n",
    "                raw_returns[tick] = stocks[tick].pct_change()\n",
    "        returns=raw_returns[1:]\n",
    "        return returns[np.isfinite(returns).all(1)]\n",
    "        \n",
    "    if(give == \"S\"):\n",
    "        return just_stocks\n",
    "    \n",
    "    if(give==\"D\"):\n",
    "        dividend = pd.DataFrame(np.array(stocks.iloc[:,len(just_stocks.columns):])/np.array(stocks.iloc[:,:len(just_stocks.columns)])).set_index(just_stocks.index)\n",
    "        dividend.columns=just_stocks.columns\n",
    "        return dividend\n",
    "    \n",
    "    #importing financial data from yahoo finance\n",
    "#commodity_futures = ['GC=F', 'SI=F', 'CL=F']\n",
    "#cryptocurrencies = ['BTC-USD', 'ETH-USD', 'XRP-USD']\n",
    "#currencies = ['EURUSD=X', 'JPY=X', 'GBPUSD=X']\n",
    "#mutual_funds = ['PRLAX', 'QASGX', 'HISFX']\n",
    "#us_treasuries = ['^TNX', '^IRX', '^TYX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMA_Backtest(SMA_len, return_len, data, initial):\n",
    "    timing = initial\n",
    "    hold = 'cash'\n",
    "    acct_value = []\n",
    "    trades=[]\n",
    "    \n",
    "    for n in range (SMA_len, len(data)-return_len-np.mod(len(data)-SMA_len, return_len),return_len): \n",
    "        #the stopping point maximises the loops us of dtaset without falling outside of it.\n",
    "        price = data.iloc[n]\n",
    "        next_price = data.iloc[n+return_len]\n",
    "        SMA = data.iloc[n-SMA_len:n].mean()\n",
    "        acct_value.append(timing)\n",
    "        if (price >= SMA) & (hold =='stock'): #the first case for when the loop checks for a price signal\n",
    "            timing = next_price/price*timing\n",
    "        elif (price >= SMA) & (hold =='cash'):#the second case for when the loop checks for a price signal\n",
    "            hold = 'stock'\n",
    "            open_position = price\n",
    "            timing = next_price/price*timing\n",
    "        elif (price < SMA) & (hold =='stock'):\n",
    "            #the third and final case for when the loop checks for a price signal else nothing happens.\n",
    "            hold ='cash'\n",
    "            close_position = price\n",
    "            if close_position > open_position:\n",
    "                trades.append(1)\n",
    "            else: \n",
    "                trades.append(0)\n",
    "    return(timing,acct_value,trades)\n",
    "\n",
    "#The SMA function,includes current day included SMA. basic form is to compare price to SMA of length set by user.\n",
    "#This function looks for another price signal after a number of days equal to the return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total daily contract volume\n",
    "\n",
    "def daily_call_volume(ticker):\n",
    "    day_vol = 0\n",
    "    exp_dates = options.get_expiration_dates(ticker)\n",
    "    for dates in exp_dates:\n",
    "        calls = options.get_calls(ticker,dates)[\"Volume\"].values\n",
    "        calls = np.where(calls == '-', 0, calls)\n",
    "        day_vol += calls.astype('int').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_relative_performance(df,select_intervals=[.02,.01,.005,0,-.005,-.01,-.02]):\n",
    "    #select_intervals = [.02,.01,0,-.01,-.02] #highest to lowest\n",
    "    outperformance = np.zeros(len(select_intervals)+1)\n",
    "    probabilities = np.zeros(len(select_intervals)+1)\n",
    "    outperformance[0] = df[df['SPY']>=select_intervals[0]].mean().diff()[1]\n",
    "    probabilities[0] = len(df[df['SPY']>=select_intervals[0]])/len(df)\n",
    "\n",
    "    for i in range(1,len(select_intervals)):\n",
    "        outperformance[i] = df[(df['SPY']<select_intervals[i-1]) & (df['SPY']>select_intervals[i])].mean().diff()[1]\n",
    "        probabilities[i] = len(df[(df['SPY']<select_intervals[i-1]) & (df['SPY']>select_intervals[i])])/len(df)\n",
    "    \n",
    "    outperformance[-1] = df[df['SPY']<=select_intervals[-1]].mean().diff()[1]\n",
    "    probabilities[-1] = len(df[df['SPY']<=select_intervals[-1]])/len(df)\n",
    "\n",
    "\n",
    "    print('Given SPY moves more than',select_intervals[0], 'SPYC outperformance is', np.round(outperformance[0],4), '    Probability:', np.round(probabilities[0],4))\n",
    "    for i in range(len(outperformance)-2):\n",
    "        print('{0: <16}'.format('Given SPY moves'), round(select_intervals[i+1],4),'to',round(select_intervals[i],4),'SPYC outperformance is',np.round(outperformance[i+1],4),'Probability:', np.round(probabilities[i+1],3) )\n",
    "    print('Given SPY moves below ',select_intervals[-1], 'SPYC outperformance is', np.round(outperformance[-1],4),'    Probability:', np.round(probabilities[-1],4))  \n",
    "    print('Expected outperformance: ', np.dot(probabilities,outperformance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
